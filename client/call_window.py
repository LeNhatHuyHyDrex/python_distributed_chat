# client/call_window.py
import subprocess
import re
import sounddevice as sd
import numpy as np
import queue
import sys

from typing import List
from PyQt6.QtCore import Qt, pyqtSignal, QSize, QEvent
from PyQt6.QtGui import QImage, QPixmap, QIcon, QColor, QResizeEvent
from PyQt6.QtWidgets import (
    QDialog, QVBoxLayout, QHBoxLayout, QLabel, QPushButton,
    QComboBox, QWidget, QFrame, QGraphicsDropShadowEffect
)

from .webrtc_session import WebRTCSession
from .network import make_packet

class CallWindow(QDialog):
    remote_frame_signal = pyqtSignal(object)
    local_frame_signal = pyqtSignal(object)

    def __init__(self, parent=None, mode="private", is_video=True, self_name="", peers=None, is_incoming=False, conv_id=None, partner_username=None):
        super().__init__(parent)
        self.main = parent
        self.mode = mode
        self.is_video = is_video
        self.self_name = self_name
        self.peers = peers or []
        self.is_incoming = is_incoming
        self.conv_id = conv_id
        self.partner_username = partner_username

        # Tr·∫°ng th√°i
        self.is_mic_muted = False
        self.is_cam_muted = False

        self.setWindowTitle(f"Cu·ªôc g·ªçi v·ªõi {self.partner_username or 'Nh√≥m'}")
        self.resize(1000, 700)
        # Set m√†u n·ªÅn ƒëen cho to√†n b·ªô c·ª≠a s·ªï
        self.setStyleSheet("background-color: #000000;")

        # K·∫øt n·ªëi Signal
        self.remote_frame_signal.connect(self.update_remote_video)
        self.local_frame_signal.connect(self.update_local_video)

        self.audio_queue = queue.Queue(maxsize=200) 
        self.audio_stream = None 

        self._build_ui()
        
        self.webrtc = WebRTCSession(self, is_video=is_video)
        self.restart_audio_stream()

    def _build_ui(self):
        # Container ch√≠nh (ƒë·ªÉ ch·ª©a c√°c layer ch·ªìng l√™n nhau)
        self.container = QWidget(self)
        # Layout ch√≠nh ch·ªâ ƒë·ªÉ set margin = 0
        main_layout = QVBoxLayout(self)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.addWidget(self.container)

        # --- LAYER 1: REMOTE VIDEO (N·ªÄN) ---
        self.remote_video = QLabel(self.container)
        self.remote_video.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.remote_video.setScaledContents(True)
        self.remote_video.setStyleSheet("background-color: #1c1c1c; color: #888; font-size: 16px;")
        self.remote_video.setText(f"ƒêang ƒë·ª£i video t·ª´ {self.partner_username}...")

        # --- LAYER 2: LOCAL VIDEO (PIP - G√≥c ph·∫£i d∆∞·ªõi) ---
        self.local_video = QLabel(self.container)
        self.local_video.setFixedSize(180, 240) # T·ªâ l·ªá 3:4 ho·∫∑c 9:16
        self.local_video.setScaledContents(True)
        # Bo g√≥c v√† vi·ªÅn nh·∫π
        self.local_video.setStyleSheet("""
            background-color: #333; 
            border: 2px solid #444; 
            border-radius: 12px;
        """)
        # Th√™m b√≥ng ƒë·ªï cho Local Video n·ªïi l√™n
        shadow = QGraphicsDropShadowEffect()
        shadow.setBlurRadius(20)
        shadow.setColor(QColor(0, 0, 0, 150))
        shadow.setOffset(0, 5)
        self.local_video.setGraphicsEffect(shadow)
        
        if not self.is_video:
            self.local_video.setVisible(False)

        # --- LAYER 3: TOP BAR (Mic/Loa selection) ---
        # L√†m thanh m·ªù ·ªü tr√™n c√πng
        self.top_bar = QFrame(self.container)
        self.top_bar.setStyleSheet("""
            QFrame {
                background-color: rgba(0, 0, 0, 100); 
                border-radius: 20px;
            }
            QLabel { color: white; font-weight: bold; background: transparent; }
            QComboBox {
                background-color: rgba(255, 255, 255, 0.1);
                color: white;
                border: 1px solid rgba(255,255,255,0.3);
                border-radius: 5px;
                padding: 2px 5px;
            }
            QComboBox QAbstractItemView {
                background-color: #333;
                color: white;
            }
        """)
        top_layout = QHBoxLayout(self.top_bar)
        top_layout.setContentsMargins(15, 8, 15, 8)
        
        self.cb_camera = QComboBox()
        self.cb_mic = QComboBox()
        self.cb_speaker = QComboBox()
        
        # Ch·ªâ hi·ªán ComboBox Camera n·∫øu l√† Video Call
        if self.is_video:
            top_layout.addWidget(QLabel("üì∑"))
            top_layout.addWidget(self.cb_camera, 1)
            top_layout.addSpacing(10)
        
        top_layout.addWidget(QLabel("üéôÔ∏è"))
        top_layout.addWidget(self.cb_mic, 1)
        top_layout.addSpacing(10)
        top_layout.addWidget(QLabel("üîä"))
        top_layout.addWidget(self.cb_speaker, 1)

        # --- LAYER 4: BOTTOM CONTROLS (N√∫t ƒëi·ªÅu khi·ªÉn) ---
        self.controls_bar = QFrame(self.container)
        self.controls_bar.setStyleSheet("""
            QFrame {
                background-color: transparent;
            }
            QPushButton {
                background-color: rgba(60, 60, 60, 0.9);
                border: none;
                border-radius: 28px; /* H√¨nh tr√≤n: 56px / 2 */
                min-width: 56px;
                min-height: 56px;
                font-size: 24px;
                color: white;
            }
            QPushButton:hover {
                background-color: rgba(90, 90, 90, 1);
            }
            QPushButton:pressed {
                background-color: rgba(120, 120, 120, 1);
            }
            /* N√∫t k·∫øt th√∫c m√†u ƒë·ªè */
            QPushButton#btn_end {
                background-color: #ff3b30;
            }
            QPushButton#btn_end:hover {
                background-color: #ff6058;
            }
            /* N√∫t tr·∫£ l·ªùi m√†u xanh */
            QPushButton#btn_answer {
                background-color: #30d158;
            }
        """)
        
        ctrl_layout = QHBoxLayout(self.controls_bar)
        ctrl_layout.setSpacing(20)
        ctrl_layout.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # N√∫t Mic
        self.btn_toggle_mic = QPushButton("üéôÔ∏è")
        self.btn_toggle_mic.setToolTip("B·∫≠t/T·∫Øt Mic")
        self.btn_toggle_mic.clicked.connect(self.on_toggle_mic)
        ctrl_layout.addWidget(self.btn_toggle_mic)

        # N√∫t Camera (Ch·ªâ hi·ªán khi Video Call)
        self.btn_toggle_cam = QPushButton("üì∑")
        self.btn_toggle_cam.setToolTip("B·∫≠t/T·∫Øt Camera")
        self.btn_toggle_cam.clicked.connect(self.on_toggle_cam)
        if self.is_video:
            ctrl_layout.addWidget(self.btn_toggle_cam)
        else:
            self.btn_toggle_cam.setVisible(False)

        # N√∫t Tr·∫£ l·ªùi (ch·ªâ hi·ªán khi c√≥ cu·ªôc g·ªçi ƒë·∫øn)
        self.btn_answer = QPushButton("üìû")
        self.btn_answer.setObjectName("btn_answer")
        self.btn_answer.clicked.connect(self.on_answer_clicked)
        if not self.is_incoming:
            self.btn_answer.setVisible(False)
        else:
            ctrl_layout.addWidget(self.btn_answer)

        # N√∫t K·∫øt th√∫c
        self.btn_end = QPushButton("‚ùå") # Ho·∫∑c icon ƒëi·ªán tho·∫°i g√°c m√°y
        self.btn_end.setObjectName("btn_end")
        self.btn_end.setToolTip("K·∫øt th√∫c")
        self.btn_end.clicked.connect(self.on_end_clicked)
        ctrl_layout.addWidget(self.btn_end)

        # --- LOGIC RESIZE (ƒê·ªÉ gi·ªØ v·ªã tr√≠ c√°c layer) ---
        self.cb_speaker.currentIndexChanged.connect(self.restart_audio_stream)
        self.populate_devices()
        self.populate_speakers()
        if not self.is_video: self.cb_camera.setEnabled(False)

    def resizeEvent(self, event: QResizeEvent):
        """
        H√†m n√†y ƒë∆∞·ª£c g·ªçi m·ªói khi c·ª≠a s·ªï thay ƒë·ªïi k√≠ch th∆∞·ªõc.
        D√πng ƒë·ªÉ t√≠nh to√°n v·ªã tr√≠ tuy·ªát ƒë·ªëi (Absolute Positioning) cho c√°c widget n·ªïi.
        """
        w = self.width()
        h = self.height()

        # 1. Remote Video: Tr√†n m√†n h√¨nh
        self.remote_video.setGeometry(0, 0, w, h)

        # 2. Local Video: G√≥c ph·∫£i d∆∞·ªõi, c√°ch l·ªÅ 20px
        # K√≠ch th∆∞·ªõc local video
        lw, lh = 180, 240 
        self.local_video.setGeometry(w - lw - 20, h - lh - 100, lw, lh) # Tr·ª´ 100px ·ªü d∆∞·ªõi ƒë·ªÉ kh√¥ng che n√∫t

        # 3. Top Bar: ·ªû tr√™n c√πng, cƒÉn gi·ªØa, c√°ch l·ªÅ tr√™n 20px
        top_w = min(600, w - 40)
        top_h = 50
        self.top_bar.setGeometry((w - top_w) // 2, 20, top_w, top_h)

        # 4. Controls Bar: ·ªû d∆∞·ªõi c√πng, cƒÉn gi·ªØa, c√°ch l·ªÅ d∆∞·ªõi 30px
        ctrl_w = min(400, w - 40)
        ctrl_h = 80
        self.controls_bar.setGeometry((w - ctrl_w) // 2, h - ctrl_h - 20, ctrl_w, ctrl_h)

        super().resizeEvent(event)

    # --- C√ÅC H√ÄM LOGIC X·ª¨ L√ù ---

    def on_toggle_mic(self):
        self.is_mic_muted = not self.is_mic_muted
        if self.is_mic_muted:
            self.btn_toggle_mic.setText("üîá") # Icon Mic g·∫°ch ch√©o
            self.btn_toggle_mic.setStyleSheet("background-color: white; color: black;") # ƒê·∫£o m√†u cho n·ªïi b·∫≠t
            self.webrtc.set_audio_enabled(False)
        else:
            self.btn_toggle_mic.setText("üéôÔ∏è")
            self.btn_toggle_mic.setStyleSheet("background-color: rgba(60, 60, 60, 0.9); color: white;")
            self.webrtc.set_audio_enabled(True)

    def on_toggle_cam(self):
        self.is_cam_muted = not self.is_cam_muted
        if self.is_cam_muted:
            self.btn_toggle_cam.setText("üö´") # Icon Cam g·∫°ch ch√©o
            self.btn_toggle_cam.setStyleSheet("background-color: white; color: black;")
            self.webrtc.set_video_enabled(False)
            # L√†m m·ªù local video
            self.local_video.setPixmap(QPixmap())
            self.local_video.setText("Camera T·∫Øt")
            self.local_video.setStyleSheet("background-color: #000; color: white; border: 2px solid #444; border-radius: 12px; qproperty-alignment: AlignCenter;")
        else:
            self.btn_toggle_cam.setText("üì∑")
            self.btn_toggle_cam.setStyleSheet("background-color: rgba(60, 60, 60, 0.9); color: white;")
            self.webrtc.set_video_enabled(True)
            # Reset style local video
            self.local_video.setText("")
            self.local_video.setStyleSheet("background-color: #333; border: 2px solid #444; border-radius: 12px;")

    # ... (Ph·∫ßn d∆∞·ªõi gi·ªØ nguy√™n logic c≈©, ch·ªâ s·ª≠a update_remote_video n·∫øu c·∫ßn) ...

    def populate_devices(self):
        self.cb_camera.clear()
        self.cb_mic.clear()
        self.cb_camera.addItem("M·∫∑c ƒë·ªãnh")
        self.cb_mic.addItem("M·∫∑c ƒë·ªãnh")
        try:
            proc = subprocess.run(["ffmpeg", "-list_devices", "true", "-f", "dshow", "-i", "dummy"], capture_output=True, text=True, encoding="utf-8")
            out = proc.stderr
            for line in out.splitlines():
                if "dshow @" in line and '"' in line:
                    m = re.search(r'"([^"]+)"', line)
                    if m:
                        name = m.group(1)
                        if "(video)" in line: self.cb_camera.addItem(name)
        except: pass
        try:
            devices = sd.query_devices()
            unique_mics = set()
            for d in devices:
                if d['max_input_channels'] > 0:
                    name = d['name']
                    if name not in unique_mics:
                        unique_mics.add(name)
                        self.cb_mic.addItem(name)
        except: pass

    def populate_speakers(self):
        self.cb_speaker.blockSignals(True)
        self.cb_speaker.clear()
        self.cb_speaker.addItem("M·∫∑c ƒë·ªãnh")
        try:
            devices = sd.query_devices()
            unique_spk = set()
            for i, d in enumerate(devices):
                if d['max_output_channels'] > 0:
                    name = d['name']
                    if name not in unique_spk:
                        unique_spk.add(name)
                        self.cb_speaker.addItem(f"{i}: {name}")
        except: pass
        self.cb_speaker.blockSignals(False)

    def audio_callback(self, outdata, frames, time, status):
        try:
            data = self.audio_queue.get_nowait()
            chunk_len = len(data)
            if chunk_len < len(outdata):
                outdata[:chunk_len] = data
                outdata[chunk_len:] = 0
            else:
                outdata[:] = data[:len(outdata)]
        except queue.Empty:
            outdata.fill(0)
        except Exception:
            outdata.fill(0)

    def restart_audio_stream(self):
        if self.audio_stream:
            self.audio_stream.stop()
            self.audio_stream.close()
            self.audio_stream = None

        spk_text = self.cb_speaker.currentText()
        device_id = None
        if ":" in spk_text:
            try: device_id = int(spk_text.split(":")[0])
            except: pass
        
        try:
            self.audio_stream = sd.OutputStream(
                samplerate=48000,
                channels=2, 
                dtype='int16',
                device=device_id,
                callback=self.audio_callback,
                blocksize=960 
            )
            self.audio_stream.start()
        except Exception as e:
            print(f"[Audio] ‚ùå L·ªói loa: {e}")

    def queue_audio_data(self, data_numpy):
        try:
            data = data_numpy.astype(np.int16)
            if data.ndim == 1: data = data.reshape(-1, 1)
            if data.shape[1] == 1: data = np.tile(data, (1, 2))
            self.audio_queue.put(data, block=False)
        except queue.Full: pass

    def get_selected_devices(self):
        cam = self.cb_camera.currentText() if self.cb_camera.currentIndex() > 0 else None
        mic = self.cb_mic.currentText() if self.cb_mic.currentIndex() > 0 else None
        return cam, mic

    def prepare_webrtc_devices(self):
        cam, mic = self.get_selected_devices()
        self.webrtc.camera_name = cam
        self.webrtc.mic_name = mic

    def update_remote_video(self, img_array):
        if not self.is_video: return
        self._safe_draw_frame(img_array, self.remote_video)

    def update_local_video(self, img_array):
        if not self.is_video: return
        if self.is_cam_muted: return
        self._safe_draw_frame(img_array, self.local_video)

    def _safe_draw_frame(self, img_array, target_label):
        if target_label is None or not target_label.isVisible(): return
        try:
            img_data = np.ascontiguousarray(img_array)
            h, w, ch = img_data.shape
            bytes_per_line = ch * w
            qimg = QImage(img_data.data, w, h, bytes_per_line, QImage.Format.Format_RGB888).copy()
            pix = QPixmap.fromImage(qimg)
            
            # V·ªõi remote video (full screen), ta ƒë·ªÉ setScaledContents lo (nh∆∞ng aspect ratio c√≥ th·ªÉ b·ªã m√©o)
            # N·∫øu mu·ªën gi·ªØ t·ªâ l·ªá chu·∫©n (c√≥ vi·ªÅn ƒëen), d√πng logic scale th·ªß c√¥ng:
            if target_label == self.remote_video:
                target_label.setPixmap(pix) # Label ƒë√£ setScaledContents(True)
            else:
                # Local video (PiP) th∆∞·ªùng c·∫ßn fill ƒë·∫ßy khung
                # ·ªû ƒë√¢y ta c·ª© setPixmap, Label s·∫Ω t·ª± scale
                target_label.setPixmap(pix)
        except Exception:
            pass

    def on_answer_clicked(self):
        self.btn_answer.setVisible(False)
        self.setWindowTitle("ƒêang k·∫øt n·ªëi...")
        self.prepare_webrtc_devices()
        reply = {"kind": "accept", "is_video": self.is_video, "to": self.partner_username}
        if self.mode == "group": reply["conversation_id"] = self.conv_id
        try:
            if self.main.sock: self.main.sock.sendall(make_packet("call_signal", reply))
        except: pass

    def on_end_clicked(self):
        try:
            data = {"kind": "bye", "is_video": self.is_video}
            if self.mode == "private": data["to"] = self.peers[0] if self.peers else None
            else: data["conversation_id"] = getattr(self.main, "current_group_id", None)
            if self.main.sock: self.main.sock.sendall(make_packet("call_signal", data))
        except: pass

        if self.audio_stream:
            self.audio_stream.stop()
            self.audio_stream.close()
        if self.webrtc:
            self.webrtc.close()
        self.accept()